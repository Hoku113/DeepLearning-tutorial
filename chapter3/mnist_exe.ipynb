{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file execute a MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# You must wait a minute for the first call\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "# outputs data\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show a MNIST Image using PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "# Show Image function\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    print(type(pil_img))\n",
    "    pil_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n",
      "<class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "# Get a MNIST data\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "\n",
    "# output property \n",
    "print(label)\n",
    "print(img.shape)\n",
    "\n",
    "# reshape Image size (28, 28)\n",
    "img = img.reshape(28, 28)\n",
    "print(img.shape)\n",
    "\n",
    "img_show(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Neural Network\n",
    "\n",
    "### Need the fllowing node\n",
    "- input layer : 784 (image size)\n",
    "- output layer : 10 (class size)\n",
    "- hidding layer1 : 50\n",
    "- hidding layer2 : 100\n",
    "\n",
    "※ Hidding layer value is able to any value you can specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes theree function\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = \\\n",
    "        load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    \n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "\n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    # weight\n",
    "    w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
    "    # bias\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, w1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, w2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, w3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9352\n",
      "Wall time: 2.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# execute neaural network\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "# debug\n",
    "# print(x) # Image property\n",
    "# print(t) # label property\n",
    "# print(network)\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y) # Get the most biggest facter of probability index\n",
    "\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {str(float(accuracy_cnt) / len(x))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing\n",
    "\n",
    "※Batch: Cohesive input data(A wad of bills image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(784,)\n",
      "(784, 50)\n",
      "(50, 100)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "x, _ = get_data()\n",
    "network = init_network()\n",
    "w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
    "\n",
    "# Shape of x parameter\n",
    "print(x.shape)\n",
    "print(x[0].shape)\n",
    "\n",
    "# Shape of w parameter\n",
    "print(w1.shape)\n",
    "print(w2.shape)\n",
    "print(w3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9352\n",
      "Wall time: 384 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # number of batch\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print(f\"Accuracy: {str(float(accuracy_cnt) / len(x))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic\n",
    "\n",
    "#### axis: Specify one dimension as the axis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "# For example\n",
    "x = np.array([[0.1, 0.8, 0.1], [0.3, 0.1, 0.6],\n",
    "[0.2, 0.5, 0.3], [0.8, 0.1, 0.1]])\n",
    "\n",
    "y = np.argmax(x, axis=1)\n",
    "print(y) # Outputs most biggest value in arrange each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1, 2, 1, 0])\n",
    "t = np.array([1, 2, 0, 0])\n",
    "\n",
    "print(y==t)\n",
    "print(np.sum(y==t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb18c271c28dc06e02396b5ad84cd588eba2203dfb423c25a9ad75e8d3653462"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
